{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwbA2dl-wzSq",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Video Face Manipulation Detection Through Ensemble of CNNs\n",
    "\n",
    "Code in this notebook is adapted from \n",
    "https://github.com/polimi-ispl/icpr2020dfdc\n",
    "\n",
    "N. Bonettini, E. D. Cannas, S. Mandelli, L. Bondi, P. Bestagini and S. Tubaro, \"Video Face Manipulation Detection Through Ensemble of CNNs,\" 2020 25th International Conference on Pattern Recognition (ICPR), 2021, pp. 5012-5019, doi: 10.1109/ICPR48806.2021.9412711.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TH96I-fxw_JU",
    "outputId": "1385acf2-c4e0-411e-dc3f-5851ae1b0d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'icpr2020dfdc'...\n",
      "remote: Enumerating objects: 645, done.\u001b[K\n",
      "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
      "remote: Total 645 (delta 96), reused 81 (delta 81), pack-reused 537\u001b[K\n",
      "Receiving objects: 100% (645/645), 99.63 MiB | 18.22 MiB/s, done.\n",
      "Resolving deltas: 100% (336/336), done.\n",
      "Collecting efficientnet-pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch) (4.2.0)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=5f46c06c43b3dbf43b0eb5fc83171a3ca196256fc1e3909a62b559c52261a4ae\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n",
      "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-dzwr0dso\n",
      "/content/icpr2020dfdc/notebook\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/polimi-ispl/icpr2020dfdc\n",
    "!pip install efficientnet-pytorch\n",
    "!pip install -U git+https://github.com/albu/albumentations > /dev/null\n",
    "%cd icpr2020dfdc/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPUuCepXBjEf",
    "outputId": "08f74afe-4dc1-4ee3-af31-8c1baa76071b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: opencv-python-headless 4.5.5.64\n",
      "Uninstalling opencv-python-headless-4.5.5.64:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.64.dist-info/*\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-65fa80df.so.58.134.100\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-8ef5c7db.so.58.76.100\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-9c768859.so.56.70.100\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-09fe7800.so.1.1\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-b92f8066.so.1.1\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-99364a1c.so.3.9.100\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-e6451464.so.5.9.100\n",
      "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-1016051d.so.7.0.0\n",
      "  Would not remove (might be manually added):\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
      "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
      "Proceed (y/n)? y\n",
      "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
      "Collecting opencv-python-headless==4.1.2.30\n",
      "  Downloading opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.8 MB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.1.2.30\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv-python-headless==4.5.5.62\n",
    "!pip install opencv-python-headless==4.1.2.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fPvvLUnIwzSs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.model_zoo import load_url\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os \n",
    "\n",
    "\n",
    "from blazeface import FaceExtractor, BlazeFace, VideoReader\n",
    "from architectures import fornet,weights\n",
    "from isplutils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3smEpNwwzSt"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "QMaTYblPwzSt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Choose an architecture between\n",
    "- EfficientNetB4\n",
    "- EfficientNetB4ST\n",
    "- EfficientNetAutoAttB4\n",
    "- EfficientNetAutoAttB4ST\n",
    "- Xception\n",
    "\"\"\"\n",
    "net_model = 'EfficientNetB4ST'\n",
    "\n",
    "\"\"\"\n",
    "Choose a training dataset between\n",
    "- DFDC\n",
    "- FFPP\n",
    "\"\"\"\n",
    "train_db = 'DFDC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "n7sIweSJwzSu"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "face_policy = 'scale'\n",
    "face_size = 224\n",
    "frames_per_video = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0rPauY4wzSv"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "8322912d413a42ad8eabaf59e608ec5a",
      "c458abce8207466a86322ee9c37bef55",
      "c0e3b59a58ba4ea88a77d1ac7a6b6a72",
      "11c193a9bac04438a2bef4762db5dc3d",
      "5d46cbebc1704320afd6840a05fb2702",
      "6a692a13624341bc80a0a7ddb77ea4ae",
      "56e81c4eed1743e8a7d9f806a403a5f4",
      "9eae1450812c4c58b048ae43df525bc3",
      "68638db2bec94c79b6b1e945717e751b",
      "3d6fac548c184444a9cfaa2e7c310bef",
      "ed14c47516c4482381bfdfe65b17c38a"
     ]
    },
    "id": "vMlZk3TSwzSv",
    "outputId": "da04e8aa-ba6f-43f2-f7ab-f5e09dc2a326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://f002.backblazeb2.com/file/icpr2020/EfficientNetB4ST_DFDC_bestval-86f0a0701b18694dfb5e7837bd09fa8e48a5146c193227edccf59f1b038181c6.pth\" to /root/.cache/torch/hub/checkpoints/EfficientNetB4ST_DFDC_bestval-86f0a0701b18694dfb5e7837bd09fa8e48a5146c193227edccf59f1b038181c6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8322912d413a42ad8eabaf59e608ec5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/33.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_url = weights.weight_url['{:s}_{:s}'.format(net_model,train_db)]\n",
    "net = getattr(fornet,net_model)().eval().to(device)\n",
    "net.load_state_dict(load_url(model_url,map_location=device,check_hash=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "sJD4-cmNwzSw"
   },
   "outputs": [],
   "source": [
    "transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "6jDS1Gs6wzSx"
   },
   "outputs": [],
   "source": [
    "facedet = BlazeFace().to(device)\n",
    "facedet.load_weights(\"../blazeface/blazeface.pth\")\n",
    "facedet.load_anchors(\"../blazeface/anchors.npy\")\n",
    "videoreader = VideoReader(verbose=False)\n",
    "video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n",
    "face_extractor = FaceExtractor(video_read_fn=video_read_fn,facedet=facedet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l37M5qzmwzSx"
   },
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "bkgxqhc-OnDQ"
   },
   "outputs": [],
   "source": [
    "model_name = net_model + '_' + train_db\n",
    "result_folder = './Res_' + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAVX5PpcCO0p",
    "outputId": "d8d05cd1-7141-4cd9-85b5-062f627a9d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with African men\n",
      "Done with African women\n",
      "Done with Caucasian (American) men\n",
      "Done with Caucasian (American) women\n",
      "Done with Caucasian (European) men\n",
      "Done with Caucasian (European) women\n",
      "Done with Asian (South) men\n",
      "Done with Asian (South) women\n",
      "Done with Asian (East) men\n",
      "Done with Asian (East) women\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "main_folder = './RealVideo-RealAudio'\n",
    "label = 0 # change this according to the folder - 0 for real and 1 for fake\n",
    "for ethnicity in os.listdir(main_folder):\n",
    "  if 'DS_Store' in ethnicity:\n",
    "    continue\n",
    "  for gender in os.listdir(os.path.join(main_folder,ethnicity)):\n",
    "    if 'DS_Store' in gender:\n",
    "      continue\n",
    "\n",
    "    paths = []\n",
    "    inputs = []\n",
    "    for video_id in os.listdir(os.path.join(main_folder,ethnicity,gender)):\n",
    "      if 'DS_Store' in video_id:\n",
    "        continue\n",
    "      for file_name in os.listdir(os.path.join(main_folder,ethnicity,gender,video_id)):\n",
    "        if file_name.endswith('.mp4'):\n",
    "          video_path = os.path.join(main_folder,ethnicity,gender,video_id,file_name)\n",
    "          frames = face_extractor.process_video(video_path)\n",
    "          faces = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in frames if len(frame['faces'])] ) # num_frames x 3 x 224 x 224\n",
    "          inputs.append(faces)\n",
    "          paths.append(video_path)\n",
    "\n",
    "    # concat inputs \n",
    "    preds = []\n",
    "    for video_input in inputs:\n",
    "      with torch.no_grad():\n",
    "        video_pred = net(video_input.to(device)).cpu().numpy().flatten()\n",
    "        video_pred = expit(video_pred.mean())\n",
    "        preds.append(video_pred)\n",
    "\n",
    "    # make diretory to store result\n",
    "    result_path_dir = os.path.join(result_folder,ethnicity,gender)\n",
    "    if not os.path.exists(result_path_dir):\n",
    "      os.makedirs(result_path_dir)\n",
    "    \n",
    "    # store result in a csv\n",
    "    df = pd.DataFrame({\n",
    "        'path': paths,\n",
    "        'ethnicity': [ethnicity] * len(paths),\n",
    "        'gender': [gender] * len(paths),\n",
    "        'pred': preds,\n",
    "        'label': [label] * len(paths)\n",
    "    })\n",
    "\n",
    "    df.to_csv(os.path.join(result_path_dir,'results.csv'),index=False)\n",
    "\n",
    "    print('Done with ' + ethnicity + ' ' + gender)\n",
    "\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnejnfJiW5n1",
    "outputId": "e32d9d7c-04ab-4861-95ff-22871bf2f6cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: Res_EfficientNetB4ST_DFDC/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/African/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/African/men/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/African/men/results.csv (deflated 82%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/African/women/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/African/women/results.csv (deflated 82%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (American)/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (American)/men/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (American)/men/results.csv (deflated 86%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (American)/women/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (American)/women/results.csv (deflated 87%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (European)/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (European)/men/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (European)/men/results.csv (deflated 87%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (European)/women/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Caucasian (European)/women/results.csv (deflated 87%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (South)/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (South)/men/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (South)/men/results.csv (deflated 84%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (South)/women/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (South)/women/results.csv (deflated 85%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (East)/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (East)/men/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (East)/men/results.csv (deflated 84%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (East)/women/ (stored 0%)\n",
      "  adding: Res_EfficientNetB4ST_DFDC/Asian (East)/women/results.csv (deflated 84%)\n"
     ]
    }
   ],
   "source": [
    "# create a zip of the result folder and download it\n",
    "!zip -r Res_EfficientNetB4ST_DFDC.zip Res_EfficientNetB4ST_DFDC/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Video_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11c193a9bac04438a2bef4762db5dc3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d6fac548c184444a9cfaa2e7c310bef",
      "placeholder": "​",
      "style": "IPY_MODEL_ed14c47516c4482381bfdfe65b17c38a",
      "value": " 33.9M/33.9M [00:01&lt;00:00, 28.2MB/s]"
     }
    },
    "3d6fac548c184444a9cfaa2e7c310bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56e81c4eed1743e8a7d9f806a403a5f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d46cbebc1704320afd6840a05fb2702": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68638db2bec94c79b6b1e945717e751b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a692a13624341bc80a0a7ddb77ea4ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8322912d413a42ad8eabaf59e608ec5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c458abce8207466a86322ee9c37bef55",
       "IPY_MODEL_c0e3b59a58ba4ea88a77d1ac7a6b6a72",
       "IPY_MODEL_11c193a9bac04438a2bef4762db5dc3d"
      ],
      "layout": "IPY_MODEL_5d46cbebc1704320afd6840a05fb2702"
     }
    },
    "9eae1450812c4c58b048ae43df525bc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0e3b59a58ba4ea88a77d1ac7a6b6a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eae1450812c4c58b048ae43df525bc3",
      "max": 35530189,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68638db2bec94c79b6b1e945717e751b",
      "value": 35530189
     }
    },
    "c458abce8207466a86322ee9c37bef55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a692a13624341bc80a0a7ddb77ea4ae",
      "placeholder": "​",
      "style": "IPY_MODEL_56e81c4eed1743e8a7d9f806a403a5f4",
      "value": "100%"
     }
    },
    "ed14c47516c4482381bfdfe65b17c38a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
